# Agent Flow Lite 工作流搭建教程

本教程面向零基础用户，手把手教你搭建 5 个实用工作流。每个教程都包含完整的操作步骤、节点配置和连线说明。

> **前置条件**：已启动前后端服务，浏览器打开 `http://localhost:5173`，并已登录。

---

## 通用操作指南

在开始搭建之前，先熟悉编辑器的基本操作：

### 进入工作流编辑器

点击左侧导航栏的「工作流」进入编辑器页面。你会看到画布上已有一个绿色的「开始节点」。

### 添加节点

画布右侧有一个可折叠的节点抽屉面板，列出了所有可用节点类型：

| 图标 | 节点类型 | 用途 |
|------|---------|------|
| ▶ | 开始节点 | 工作流入口，接收用户输入 |
| 🤖 | LLM 节点 | 调用 AI 大模型 |
| 📚 | 知识库节点 | 从知识库检索相关文档 |
| ⚡ | 条件节点 | 根据条件分支走不同路径 |
| 🎯 | 技能节点 | 调用已创建的技能 |
| ⏹ | 结束节点 | 工作流出口，输出最终结果 |

**添加方式（二选一）**：
- **拖拽**：从右侧抽屉把节点拖到画布上想要的位置
- **点击**：直接点击抽屉中的节点类型，节点会自动出现在画布上

### 连接节点

1. 将鼠标移到节点右侧的小圆点（输出端口）上，圆点会变蓝
2. 按住鼠标左键，拖动到目标节点左侧的小圆点（输入端口）
3. 松开鼠标，连线自动生成

> 条件节点比较特殊，它有两个输出端口：右侧绿色端口代表 `true`（条件成立），下方红色端口代表 `false`（条件不成立）。

### 配置节点

1. 单击画布上的任意节点
2. 右侧弹出配置面板（360px 宽）
3. 填写该节点的配置项
4. 点击「保存」按钮

### 保存与运行

- **保存**：点击顶部工具栏的「保存工作流」按钮。首次保存会要求输入工作流名称。
- **运行**：点击「运行工作流」按钮，在弹出的对话框中输入测试内容，点击执行。你会看到实时的执行日志和最终输出。

---

## 工作流一：智能客服问答（RAG 增强）

**目标**：用户提问 → 从知识库检索相关资料 → AI 结合资料回答问题。

**节点结构**：

```
开始节点 → 知识库节点 → LLM 节点 → 结束节点
```

### 前置准备

确保你已经在「知识库」页面上传了至少一份文档（比如产品手册、FAQ 文档等），并记住该知识库的名称。

### 第一步：添加节点

画布上已有一个「开始节点」。从右侧抽屉依次添加以下节点：

1. 拖入一个 📚 **知识库节点**，放在开始节点右侧
2. 拖入一个 🤖 **LLM 节点**，放在知识库节点右侧
3. 拖入一个 ⏹ **结束节点**，放在 LLM 节点右侧

画布上现在应该有 4 个节点，从左到右排列。

### 第二步：连接节点

按以下顺序连线：

1. 从「开始节点」右侧端口 → 拖到「知识库节点」左侧端口
2. 从「知识库节点」右侧端口 → 拖到「LLM 节点」左侧端口
3. 从「LLM 节点」右侧端口 → 拖到「结束节点」左侧端口

### 第三步：配置各节点

**配置开始节点**：
1. 点击「开始节点」
2. 输入变量名填写：`user_question`
3. 点击「保存」

**配置知识库节点**：
1. 点击「知识库节点」
2. 在「选择知识库」下拉框中，选择你之前创建的知识库
3. 点击「保存」

**配置 LLM 节点**：
1. 点击「LLM 节点」
2. 在「系统提示词」文本框中输入：

```
你是一个专业的客服助手。请根据以下参考资料回答用户的问题。
如果参考资料中没有相关信息，请如实告知用户你无法回答。
不要编造信息。

参考资料：
{{knowledge-node-id.output}}

用户问题：
{{start-node-id.output}}
```

> **重要提示**：`{{knowledge-node-id.output}}` 和 `{{start-node-id.output}}` 中的 `knowledge-node-id` 和 `start-node-id` 需要替换为实际的节点 ID。你可以点击对应节点，在配置面板顶部看到节点 ID。

3. 温度滑块拖到偏左位置（约 0.2），让回答更精确
4. 点击「保存」

**结束节点**无需额外配置。

### 第四步：保存并运行

1. 点击顶部「保存工作流」，输入名称：`智能客服问答`
2. 点击「运行工作流」
3. 在输入框中输入一个与你知识库内容相关的问题，例如：`这个产品支持哪些功能？`
4. 点击执行，观察实时输出

你会看到：
- 知识库节点先检索出相关文档片段
- LLM 节点结合检索结果生成回答
- 最终输出显示在「输出」区域

---

## 工作流二：内容质量审核

**目标**：提交文章 → AI 判断质量是否达标 → 达标则润色输出，不达标则给出修改建议。

**节点结构**：

```
开始节点 → LLM(审核) → 条件节点 → [true]  LLM(润色) → 结束节点A
                                → [false] LLM(反馈) → 结束节点B
```

### 第一步：添加节点

从右侧抽屉依次添加：

1. 🤖 **LLM 节点**（审核用）— 放在开始节点右侧
2. ⚡ **条件节点** — 放在审核 LLM 右侧
3. 🤖 **LLM 节点**（润色用）— 放在条件节点的右上方
4. 🤖 **LLM 节点**（反馈用）— 放在条件节点的右下方
5. ⏹ **结束节点** — 放在润色 LLM 右侧
6. ⏹ **结束节点** — 放在反馈 LLM 右侧

> 提示：可以用鼠标拖动节点调整位置，让布局更清晰。也可以点击工具栏的「自动布局」按钮。

### 第二步：连接节点

1. 「开始节点」→「LLM(审核)」
2. 「LLM(审核)」→「条件节点」
3. 「条件节点」**右侧绿色端口（true）** →「LLM(润色)」
4. 「条件节点」**下方红色端口（false）** →「LLM(反馈)」
5. 「LLM(润色)」→「结束节点A」
6. 「LLM(反馈)」→「结束节点B」

### 第三步：配置各节点

**配置开始节点**：
- 输入变量名：`article`
- 保存

**配置 LLM(审核) 节点**：
- 系统提示词：

```
你是一个内容质量审核员。请审核以下文章的质量。
评估标准：结构清晰、逻辑通顺、无明显错误、有实质内容。

请只回答一个词：true（质量达标）或 false（质量不达标）。
不要输出任何其他内容。

文章内容：
{{start-node-id.output}}
```

- 温度：0.1（需要确定性判断）
- 保存

**配置条件节点**：
- 条件表达式：

```
"true" in "{{llm-review-node-id.output}}"
```

> 将 `llm-review-node-id` 替换为审核 LLM 节点的实际 ID。

- 保存

**配置 LLM(润色) 节点**：
- 系统提示词：

```
你是一个专业的文字编辑。请对以下文章进行润色，提升文字表达质量。
保持原文核心观点不变，优化措辞、段落结构和可读性。
直接输出润色后的文章，不要加任何说明。

原文：
{{start-node-id.output}}
```

- 温度：0.5
- 保存

**配置 LLM(反馈) 节点**：
- 系统提示词：

```
你是一个内容质量顾问。以下文章未通过质量审核。
请给出具体的修改建议，包括：
1. 主要问题是什么
2. 哪些段落需要重写
3. 结构上如何改进

文章内容：
{{start-node-id.output}}
```

- 温度：0.4
- 保存

### 第四步：保存并运行

1. 保存工作流，命名为：`内容质量审核`
2. 运行工作流，粘贴一篇文章作为输入
3. 观察执行流程：
   - 审核 LLM 输出 `true` 或 `false`
   - 条件节点根据结果分流
   - 走到润色分支或反馈分支

---

## 工作流三：多语言翻译 + 校对

**目标**：输入中文 → AI 翻译为英文 → AI 对照原文校对译文 → 输出最终译文。

**节点结构**：

```
开始节点 → LLM(翻译) → LLM(校对) → 结束节点
```

### 第一步：添加节点

1. 🤖 **LLM 节点**（翻译用）— 放在开始节点右侧
2. 🤖 **LLM 节点**（校对用）— 放在翻译 LLM 右侧
3. ⏹ **结束节点** — 放在校对 LLM 右侧

### 第二步：连接节点

1. 「开始节点」→「LLM(翻译)」
2. 「LLM(翻译)」→「LLM(校对)」
3. 「LLM(校对)」→「结束节点」

### 第三步：配置各节点

**配置开始节点**：
- 输入变量名：`source_text`
- 保存

**配置 LLM(翻译) 节点**：
- 系统提示词：

```
你是一个专业的中英翻译。请将以下中文文本翻译为英文。
要求：
- 准确传达原文含义
- 语言自然流畅，符合英文表达习惯
- 专业术语翻译准确
- 只输出英文译文，不要加任何说明

中文原文：
{{start-node-id.output}}
```

- 温度：0.3
- 保存

**配置 LLM(校对) 节点**：
- 系统提示词：

```
你是一个专业的翻译校对员。请对照中文原文检查英文译文的质量。

检查要点：
- 是否有漏译或误译
- 语法是否正确
- 表达是否自然
- 术语是否一致

如果发现问题，请直接输出修正后的完整译文。
如果译文质量良好，直接输出原译文即可。
不要输出校对说明，只输出最终英文译文。

中文原文：
{{start-node-id.output}}

英文译文：
{{llm-translate-node-id.output}}
```

> 将 `start-node-id` 和 `llm-translate-node-id` 替换为实际节点 ID。

- 温度：0.2
- 保存

### 第四步：保存并运行

1. 保存工作流，命名为：`中英翻译校对`
2. 运行工作流，输入一段中文，例如：

```
人工智能正在深刻改变我们的生活方式。从智能手机上的语音助手，到自动驾驶汽车，
AI 技术已经渗透到日常生活的方方面面。然而，随着技术的快速发展，
我们也需要认真思考 AI 带来的伦理和安全挑战。
```

3. 观察执行过程：翻译 LLM 先输出初稿，校对 LLM 对照原文修正后输出终稿

---

## 工作流四：技术方案生成器（Skill 联动）

**目标**：输入需求描述 → 检索相关技术文档 → 调用技能生成方案 → AI 评审方案 → 输出方案 + 评审意见。

**节点结构**：

```
开始节点 → 知识库节点 → LLM(方案生成) → LLM(评审) → 结束节点
```

> 说明：如果你已创建了相关技能（如技术写作技能），可以将中间的 LLM 节点替换为技能节点。本教程使用 LLM 节点演示，更通用。

### 第一步：添加节点

1. 📚 **知识库节点** — 放在开始节点右侧
2. 🤖 **LLM 节点**（方案生成）— 放在知识库节点右侧
3. 🤖 **LLM 节点**（评审）— 放在方案生成 LLM 右侧
4. ⏹ **结束节点** — 放在评审 LLM 右侧

### 第二步：连接节点

1. 「开始节点」→「知识库节点」
2. 「知识库节点」→「LLM(方案生成)」
3. 「LLM(方案生成)」→「LLM(评审)」
4. 「LLM(评审)」→「结束节点」

### 第三步：配置各节点

**配置开始节点**：
- 输入变量名：`requirement`
- 保存

**配置知识库节点**：
- 选择一个包含技术文档的知识库（如果没有，先去「知识库」页面上传一些技术文档）
- 保存

**配置 LLM(方案生成) 节点**：
- 系统提示词：

```
你是一个资深技术架构师。请根据用户需求和参考资料，生成一份技术方案。

方案格式：
## 需求分析
（简要分析需求要点）

## 技术选型
（推荐的技术栈及理由）

## 架构设计
（整体架构描述）

## 实施步骤
（分阶段的实施计划）

## 风险评估
（潜在风险及应对措施）

参考资料：
{{knowledge-node-id.output}}

用户需求：
{{start-node-id.output}}
```

- 温度：0.5
- 保存

**配置 LLM(评审) 节点**：
- 系统提示词：

```
你是一个技术评审专家。请对以下技术方案进行评审。

评审维度：
1. 可行性：方案是否可落地实施
2. 完整性：是否覆盖了需求的所有要点
3. 风险：是否有遗漏的技术风险
4. 改进建议：具体可以优化的地方

请先给出总体评分（1-10 分），然后逐条给出评审意见。

原始需求：
{{start-node-id.output}}

技术方案：
{{llm-plan-node-id.output}}
```

> 将 `llm-plan-node-id` 替换为方案生成 LLM 节点的实际 ID。

- 温度：0.3
- 保存

### 第四步：保存并运行

1. 保存工作流，命名为：`技术方案生成器`
2. 运行工作流，输入需求描述，例如：

```
我们需要为公司内部搭建一个知识管理系统，支持文档上传、全文检索、
智能问答功能。预计用户量 200 人，文档量 10 万篇。
```

3. 观察执行过程：知识库检索 → 方案生成 → 方案评审 → 最终输出

---

## 工作流五：条件路由分发器

**目标**：用户提问 → AI 识别问题类型 → 技术问题走知识库增强路径，非技术问题走通用回答路径。

**节点结构**：

```
开始节点 → LLM(意图识别) → 条件节点 → [true]  知识库节点 → LLM(技术回答) → 结束节点A
                                    → [false] LLM(通用回答) → 结束节点B
```

### 第一步：添加节点

1. 🤖 **LLM 节点**（意图识别）— 放在开始节点右侧
2. ⚡ **条件节点** — 放在意图识别 LLM 右侧
3. 📚 **知识库节点** — 放在条件节点的右上方
4. 🤖 **LLM 节点**（技术回答）— 放在知识库节点右侧
5. 🤖 **LLM 节点**（通用回答）— 放在条件节点的右下方
6. ⏹ **结束节点** — 放在技术回答 LLM 右侧
7. ⏹ **结束节点** — 放在通用回答 LLM 右侧

### 第二步：连接节点

1. 「开始节点」→「LLM(意图识别)」
2. 「LLM(意图识别)」→「条件节点」
3. 「条件节点」**右侧绿色端口（true）** →「知识库节点」
4. 「知识库节点」→「LLM(技术回答)」
5. 「LLM(技术回答)」→「结束节点A」
6. 「条件节点」**下方红色端口（false）** →「LLM(通用回答)」
7. 「LLM(通用回答)」→「结束节点B」

### 第三步：配置各节点

**配置开始节点**：
- 输入变量名：`user_input`
- 保存

**配置 LLM(意图识别) 节点**：
- 系统提示词：

```
你是一个意图识别助手。请判断用户的问题是否属于技术类问题。

技术类问题包括：编程、软件使用、系统配置、Bug 排查、架构设计、数据库、网络等。
非技术类问题包括：闲聊、生活咨询、情感问题、新闻时事、通用知识等。

请只回答一个词：true（技术问题）或 false（非技术问题）。

用户问题：
{{start-node-id.output}}
```

- 温度：0.1
- 保存

**配置条件节点**：
- 条件表达式：

```
"true" in "{{llm-intent-node-id.output}}"
```

> 将 `llm-intent-node-id` 替换为意图识别 LLM 节点的实际 ID。

- 保存

**配置知识库节点**：
- 选择包含技术文档的知识库
- 保存

**配置 LLM(技术回答) 节点**：
- 系统提示词：

```
你是一个技术支持专家。请根据参考资料回答用户的技术问题。
如果参考资料不足以回答，请结合你的专业知识给出建议，并注明哪些是来自文档、哪些是你的补充。

参考资料：
{{knowledge-node-id.output}}

用户问题：
{{start-node-id.output}}
```

- 温度：0.3
- 保存

**配置 LLM(通用回答) 节点**：
- 系统提示词：

```
你是一个友好的智能助手。请回答用户的问题。
保持回答简洁、有帮助。如果问题超出你的能力范围，请坦诚告知。

用户问题：
{{start-node-id.output}}
```

- 温度：0.6
- 保存

### 第四步：保存并运行

1. 保存工作流，命名为：`智能路由分发`
2. 运行工作流，分别测试两种类型的问题：

**测试技术问题**：
```
Python 中如何实现异步编程？async/await 的使用场景是什么？
```

**测试非技术问题**：
```
推荐几本适合周末阅读的书吧
```

3. 观察两次执行走了不同的分支路径

---

## 常见问题

### Q: 节点 ID 在哪里看？

点击画布上的任意节点，右侧配置面板会弹出。在「节点配置」标题下方有一行灰色区域，显示「节点 ID：xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx」。点击 ID 文本可以全选，直接复制粘贴到 `{{node-id.output}}` 模板中即可。

### Q: 条件表达式怎么写？

条件表达式使用 Python 语法，支持基本的比较和字符串操作：
- `"true" in "{{node-id.output}}"` — 检查输出是否包含 "true"
- `len("{{node-id.output}}") > 100` — 检查输出长度
- `"{{node-id.output}}" == "yes"` — 精确匹配

### Q: 运行时报错怎么办？

1. 检查所有节点是否都已正确配置并保存
2. 检查连线是否完整（每个节点都要有输入和输出连线，开始节点除外只需输出，结束节点只需输入）
3. 检查 `{{node-id.output}}` 中的节点 ID 是否正确
4. 查看运行对话框中的「事件」日志，定位具体是哪个节点出错

### Q: 可以复用已有的技能吗？

可以。添加 🎯 技能节点，在配置面板中选择已创建的技能。技能节点会自动显示该技能需要的输入参数，你可以将上游节点的输出映射为技能的输入。
