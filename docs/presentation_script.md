# Agent Flow Lite - 5分钟演示脚本

## 演示准备
- **项目名称**：Agent Flow Lite（简化版 Coze 智能体平台）
- **技术栈**：Python FastAPI + Vue3 + LlamaIndex + ChromaDB
- **核心功能**：可视化工作流编排、RAG 知识检索、智能问答
- **前置条件**：确保后端服务已启动、前端可访问

---

## [0:00-0:30] 开场：项目介绍 + 技术选型

### 操作步骤
1. 打开浏览器，访问 `http://localhost:5173`
2. 稍等页面加载

### 解说词
"各位老师、同学好，今天我演示的是 **Agent Flow Lite**——一个简化版的 Coze 智能体平台。

这个平台的核心价值是：**让非技术用户也能通过可视化拖拽，快速搭建 AI 智能体工作流**。

技术栈方面，我们采用 **Python FastAPI 作为后端，Vue3 作为前端**，配合 **LlamaIndex 和 ChromaDB** 实现 RAG 知识检索功能。

下面我来演示三个核心功能。"

### 屏幕显示
- 浏览器显示 Agent Flow 首页
- 顶部导航栏：Agent Flow Logo + 导航链接（首页、工作流、知识库、对话）
- 左侧边栏：相同的导航链接
- 主内容区：空白或首页内容

---

## [0:30-1:30] 演示 1：创建工作流（拖拽节点 → 配置 → 保存）

### 操作步骤
1. 点击顶部导航栏或左侧边栏的 **"工作流"** 链接
2. 从左侧节点面板 **拖拽** "开始节点"到画布中央
3. 继续拖拽一个 **"LLM 节点"** 到开始节点右侧
4. 继续拖拽一个 **"知识库节点"** 到 LLM 节点右侧
5. 点击画布上的节点，进行简单的连接（拖拽连接点）
6. 点击左侧节点面板顶部的 **"保存工作流"** 按钮
7. 在弹出对话框中输入工作流名称：**"演示工作流"**
8. 点击确定，看到成功提示

### 解说词
"首先演示工作流编排功能。

我现在点击进入 **'工作流'** 页面，大家可以看到左侧是节点面板，右侧是可视化画布。

从左侧拖拽 **'开始节点'**、**'LLM 节点'** 和 **'知识库节点'** 到画布上。

然后通过拖拽节点之间的连接点，将它们串联起来，形成一个简单的 AI 处理流程。

完成后，点击左侧的 **'保存工作流'** 按钮，输入名称 **'演示工作流'**，系统提示保存成功。

整个过程无需写代码，完全通过可视化拖拽完成，非常直观。"

### 屏幕显示
- 左侧：节点面板（保存工作流/加载工作流按钮 + 节点列表：▶ 开始节点、🤖 LLM 节点、📚 知识库节点）
- 右侧：Vue Flow 画布，显示拖拽的三个节点和连接线
- 弹窗：提示"工作流保存成功！"

---

## [1:30-2:30] 演示 2：上传文档到知识库

### 操作步骤
1. 点击顶部导航栏或左侧边栏的 **"知识库"** 链接
2. 点击页面右上角的 **"+ 新建知识库"** 按钮
3. 在弹出对话框中输入知识库名称：**"产品文档库"**
4. 点击 **"创建"** 按钮
5. 点击知识库卡片进入详情页
6. 点击上传区域的 **"点击选择文件"** 按钮
7. 选择一个测试文档（如 `test_doc.txt`）
8. 观察上传进度条从 0% 跑到 100%
9. 等待文档状态从"处理中"变为"已完成"

### 解说词
"接下来演示知识库管理功能。

点击 **'知识库'** 进入知识库管理页面。

首先创建一个新的知识库，点击右上角的 **'+ 新建知识库'**，输入名称 **'产品文档库'**。

进入知识库后，这里有一个拖拽上传区域，支持 .txt 和 .md 格式。

我点击上传一个测试文档，可以看到上传进度实时显示。

上传完成后，系统会自动对文档进行分片、向量化处理，状态会从'处理中'变成'已完成'。

这些文档就是后续智能问答的知识来源。"

### 屏幕显示
- 知识库列表页：显示"产品文档库"卡片
- 知识库详情页：
  - 顶部："← 返回列表" + "产品文档库" + 文档数量
  - 上传区域：虚线边框，显示"点击选择文件 或拖拽文件到此处"
  - 上传进度：进度条从 0% 跑到 100%，状态"上传中" → "处理中" → "完成"
  - 文档列表：显示上传的文档及其状态（绿色"已完成"徽章）

---

## [2:30-4:00] 演示 3：智能问答（展示 RAG 效果）

### 操作步骤
1. 点击顶部导航栏或左侧边栏的 **"对话"** 链接
2. 在输入框中输入问题：**"什么是 RAG？"**
3. 点击 **"发送"** 按钮
4. 观察思维链显示：**"💭 思考中：查询知识库..."**
5. 等待 AI 返回答案，答案中包含 **"[引用: xxx]"** 标记
6. 继续输入第二个问题：**"ChromaDB 支持哪些向量操作？"**
7. 点击发送，观察新的回答

### 解说词
"现在演示核心功能——智能问答，这里体现了 RAG 技术的价值。

点击 **'对话'** 进入聊天界面。

我输入一个问题：**'什么是 RAG？'**，点击发送。

大家可以看到，AI 在回答前会先显示 **思维链**——'💭 思考中：查询知识库...'，这说明它正在从我们刚才上传的知识库中检索相关信息。

AI 返回的答案中，可以看到 **[引用: xxx]** 这样的标记，这些信息直接来自我们的知识库文档，而不是凭空生成。

我再问一个技术问题：**'ChromaDB 支持哪些向量操作？'**，AI 同样能准确回答，并标注来源。

这就是 RAG 的威力——让 AI 基于真实文档回答问题，避免了幻觉问题。"

### 屏幕显示
- 左侧边栏：会话列表
- 主聊天区：
  - 用户消息（右侧气泡，深色）："什么是 RAG？"
  - 思维链（中间浅橙色框）："💭 思考中：查询知识库..."
  - AI 消息（左侧气泡，白色，带边框）："RAG（Retrieval-Augmented Generation）是一种结合检索和生成的技术... [引用: 产品文档.txt]"
  - 用户消息："ChromaDB 支持哪些向量操作？"
  - AI 消息："ChromaDB 支持向量插入、查询、删除等操作... [引用: 技术文档.md]"

---

## [4:00-5:00] 收尾：总结 + 感谢

### 操作步骤
1. 刷新浏览器页面，回到首页
2. 快速切换导航栏，展示三个主要页面（工作流、知识库、对话）
3. 等待观众

### 解说词
"总结一下，Agent Flow Lite 的三个核心亮点：

**第一，可视化工作流编排**——通过拖拽就能搭建复杂的 AI 处理流程，降低使用门槛。

**第二，灵活的知识库管理**——支持多知识库、批量上传、实时处理，适合企业级应用。

**第三，基于 RAG 的智能问答**——结合思维链展示和引用溯源，让 AI 回答更可靠、更透明。

这个平台虽然是简化版，但已经具备了智能体平台的核心能力，适合用于教学演示和快速原型验证。

以上就是我的演示，谢谢大家！"

### 屏幕显示
- 快速切换页面：
  - 工作流页面：展示已保存的"演示工作流"
  - 知识库页面：展示"产品文档库"及其文档
  - 对话页面：展示完整的对话历史和引用标记

---

## 演示注意事项

### 时间控制
- 每个阶段严格控制时间，总时长不超过 5 分钟
- 上传文档时可能需要等待 5-10 秒，这段时间可以继续解说知识库功能
- 智能问答的打字机效果可能较慢，可以适当加快演示节奏

### 备选方案
- 如果上传文档失败，提前准备好已上传的知识库，直接使用
- 如果 AI 回答速度慢，准备一个测试文档，快速展示静态结果
- 如果界面卡顿，提前截图作为备用展示

### 演示前检查清单
- [ ] 后端服务正常运行（`python main.py`）
- [ ] 前端可访问（`npm run dev`）
- [ ] 至少有一个已上传的知识库和文档
- [ ] 准备好测试问题（关于已上传文档内容的问题）
- [ ] 浏览器全屏演示模式
- [ ] 确认网络连接稳定

### 应对技巧
- 如果上传失败："演示环境网络波动，我使用已上传的知识库继续演示"
- 如果 AI 回答慢："RAG 需要检索大量数据，实际生产环境会优化响应速度"
- 如果界面卡顿："当前是开发环境，生产版会有更好的性能优化"

---

## 附录：测试问题示例

### 基于已上传文档的问题
- "什么是 RAG？"
- "LlamaIndex 的主要功能有哪些？"
- "ChromaDB 支持哪些向量操作？"
- "FastAPI 的优势是什么？"

### 不依赖特定文档的通用问题
- "介绍一下你的技术架构"
- "你的核心功能有哪些"
- "如何创建一个新的知识库"

---

## 版本信息
- **创建日期**：2026-02-02
- **适用版本**：Agent Flow Lite v1.0
- **演示时长**：5 分钟
